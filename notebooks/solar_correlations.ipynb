{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e92247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "time_column: str = \"Time\"\n",
    "satellite_name: str = \"grifex\"\n",
    "\n",
    "artifacts_dir: Path = f\"../artifacts/{satellite_name}\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "satellites_dir: Path = \"../data/satellites\"\n",
    "solar_dir: Path = \"../data/solar\"\n",
    "\n",
    "model_cfg: Path = \"../cfg/model.json\"\n",
    "\n",
    "output_graph_file: Path = f\"{artifacts_dir}/{satellite_name}_graph.json\"\n",
    "\n",
    "\n",
    "def read_satellite_data(path: Path) -> pd.DataFrame:\n",
    "    all_files = glob.glob(f\"{path}/*.csv\")\n",
    "    df = (\n",
    "        pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "        .groupby(time_column, as_index=False)\n",
    "        .mean()\n",
    "    )\n",
    "    df[time_column] = pd.to_datetime(df[time_column]).dt.normalize()\n",
    "    df = df.select_dtypes(include=[\"number\", \"bool\", \"datetime\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "satellite_data = read_satellite_data(f\"{satellites_dir}/{satellite_name}\")\n",
    "satellite_columns: list[str] = satellite_data.drop(time_column, axis=1).columns\n",
    "\n",
    "print(satellite_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c19e5b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 4 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 30\u001b[0m\n\u001b[1;32m     22\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m     23\u001b[0m     swpc_observed_ssn[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObsdate\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m     24\u001b[0m     swpc_observed_solar_cycle_indicies[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime-tag\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m     25\u001b[0m     swpc_dgd[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m     26\u001b[0m     fluxtable[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfluxdate\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     27\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Переименование столбцов и удаление дубликатов\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Сброс индекса\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 4 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "def read_solar_data(file_path: Path, date_column: str) -> pd.DataFrame:\n",
    "    df = pd.read_json(file_path)\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    return df\n",
    "\n",
    "\n",
    "swpc_observed_ssn = read_solar_data(\n",
    "    f\"{solar_dir}/swpc/swpc_observed_ssn.json\", \"Obsdate\"\n",
    ")\n",
    "\n",
    "swpc_observed_solar_cycle_indicies = read_solar_data(\n",
    "    f\"{solar_dir}/swpc/observed-solar-cycle-indices.json\", \"time-tag\"\n",
    ")\n",
    "\n",
    "swpc_dgd = pd.read_csv(f\"{solar_dir}/swpc/dgd.csv\")\n",
    "swpc_dgd[\"Date\"] = pd.to_datetime(swpc_dgd[\"Date\"])\n",
    "\n",
    "fluxtable = pd.read_csv(f\"{solar_dir}/penticton/fluxtable.txt\", delim_whitespace=True)\n",
    "fluxtable[\"fluxdate\"] = pd.to_datetime(fluxtable[\"fluxdate\"])\n",
    "\n",
    "dynamics = pd.merge(\n",
    "    satellite_data, swpc_observed_ssn, left_on=time_column, right_on=\"Obsdate\", how=\"left\"\n",
    ").drop(columns=[\"Obsdate\"])\n",
    "\n",
    "dynamics = pd.merge(\n",
    "    dynamics,\n",
    "    swpc_observed_solar_cycle_indicies,\n",
    "    left_on=time_column,\n",
    "    right_on=\"time-tag\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"time-tag\"])\n",
    "\n",
    "dynamics = pd.merge(\n",
    "    dynamics,\n",
    "    swpc_dgd,\n",
    "    left_on=time_column,\n",
    "    right_on=\"Date\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"Date\"])\n",
    "\n",
    "dynamics = pd.merge(\n",
    "    dynamics,\n",
    "    fluxtable,\n",
    "    left_on=time_column,\n",
    "    right_on=\"fluxdate\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"fluxdate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaff7f9",
   "metadata": {},
   "source": [
    "# Dependency Graph Based on Highest Correlation\n",
    "\n",
    "In this analysis, we compute the correlation between different variables in a dataset and visualize the relationships using a dependency graph. The following mathematical concepts are involved in this process:\n",
    "\n",
    "## 1. Correlation Coefficient\n",
    "\n",
    "The correlation coefficient quantifies the degree to which two variables are related. It is calculated using the formula:\n",
    "\n",
    "$$\n",
    "r_{xy} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $r_{xy}$ is the correlation coefficient between variables $X$ and $Y$.\n",
    "- $\\text{Cov}(X, Y)$ is the covariance between $X$ and $Y$.\n",
    "- $\\sigma_X$ is the standard deviation of variable $X$.\n",
    "- $\\sigma_Y$ is the standard deviation of variable $Y$.\n",
    "\n",
    "## 2. Covariance\n",
    "\n",
    "Covariance measures how much two random variables vary together. It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X, Y) = E\\left[(X - E[X])(Y - E[Y])\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $E[X]$ is the expected value (mean) of $X$.\n",
    "- $E[Y]$ is the expected value (mean) of $Y$.\n",
    "\n",
    "## 3. Maximum Correlation\n",
    "\n",
    "For each variable in the dataset, we find the variable with which it has the highest correlation. This is represented mathematically as:\n",
    "\n",
    "$$\n",
    "\\text{max\\_corr}(X) = \\arg\\max_{Y} r_{XY}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $X$ is a variable from the dataset.\n",
    "- $Y$ represents all other variables in the dataset.\n",
    "- $r_{XY}$ is the correlation coefficient between $X$ and $Y$.\n",
    "\n",
    "## 4. Graph Representation\n",
    "\n",
    "The relationships are represented as a graph where:\n",
    "- Each node represents a variable.\n",
    "- Each edge represents a relationship based on maximum correlation.\n",
    "\n",
    "### Nodes\n",
    "Each unique variable is added as a node:\n",
    "\n",
    "$$\n",
    "\\text{nodes} = \\{ \"name\": X, \"name\": Y, ...\\}\n",
    "$$\n",
    "\n",
    "\n",
    "### Edges\n",
    "An edge is created from each variable to its maximum correlated variable:\n",
    "\n",
    "$$\n",
    "\\text{edges} = \\{ \"source\": X, \"target\": Y\\}\n",
    "$$\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The resulting graph visualizes how each variable relates to its most correlated counterpart, providing insights into dependencies within the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e365e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "\n",
    "non_time_measurements = dynamics.drop(time_column, axis=1)\n",
    "\n",
    "def render_dependency_graph(df: pd.DataFrame, top_n: int = 5) -> Graph:\n",
    "    nodes: Graph.Sequence[Graph.GraphNode] = []\n",
    "    edges: Graph.Sequence[Graph.GraphLink] = []\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    for column in df.columns:\n",
    "        correlations = correlation_matrix[column].drop(column).dropna()\n",
    "\n",
    "        if not correlations.empty:\n",
    "            top_correlations = correlations.nlargest(top_n)\n",
    "\n",
    "            for _, (corr_col, corr_value) in enumerate(top_correlations.items()):\n",
    "                if {\"name\": column} not in nodes:\n",
    "                    nodes.append({\"name\": column})\n",
    "                if {\"name\": corr_col} not in nodes:\n",
    "                    nodes.append({\"name\": corr_col})\n",
    "\n",
    "                edges.append({\"source\": column, \"target\": corr_col, \"value\": corr_value})\n",
    "\n",
    "    return (\n",
    "        Graph()\n",
    "        .add(\"\", nodes=nodes, links=edges, layout=\"circular\", is_rotate_label=True)\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title=\"Dependency Graph Based on Highest Correlations\"\n",
    "            ),\n",
    "            tooltip_opts=opts.TooltipOpts(trigger=\"item\", formatter=\"{c}\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "render_dependency_graph(non_time_measurements, top_n=5).render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07370e3a",
   "metadata": {},
   "source": [
    "## Mathematical Representation\n",
    "\n",
    "The objective function can be represented mathematically as:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $y$ is the true value,\n",
    "- $\\hat{y}$ is the predicted value, and\n",
    "- $N$ is the number of instances.\n",
    "\n",
    "This formula represents the mean squared error (MSE), which measures the average of the squares of the errors—that is, the average squared difference between the estimated values ($\\hat{y}$) and the actual value ($y$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112af8f",
   "metadata": {},
   "source": [
    "# Cross-Correlation Calculation in Polaris-ML\n",
    "\n",
    "This document describes the mathematical representation of cross-correlation as implemented in Polaris-ML, referencing the configuration provided for XGBoost.\n",
    "\n",
    "## Mathematical Representation\n",
    "\n",
    "Cross-correlation measures the similarity between two signals as a function of the time-lag applied to one of them. For discrete signals $ A $ and $ B $, the cross-correlation $ R_{AB}(\\tau) $ can be defined as:\n",
    "\n",
    "$$\n",
    "R_{AB}(\\tau) = \\sum_{n=-\\infty}^{\\infty} A[n] B[n + \\tau]\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $ R_{AB}(\\tau) $ is the cross-correlation function at lag $ \\tau $,\n",
    "- $ A[n] $ is the signal $ A $ at time index $ n $,\n",
    "- $ B[n + \\tau] $ is the signal $ B $ shifted by $ \\tau $.\n",
    "\n",
    "In practical applications, when dealing with finite-length sequences, this can be expressed as:\n",
    "\n",
    "$$\n",
    "R_{AB}(\\tau) = \\sum_{n=0}^{N-1} A[n] B[n + \\tau]\n",
    "$$\n",
    "\n",
    "\n",
    "for $ -M < \\tau < N-1 $, where:\n",
    "- $ N $ is the length of signal $ A $,\n",
    "- $ M $ is the length of signal $ B $.\n",
    "\n",
    "### Normalization\n",
    "\n",
    "To reduce the influence of changes in brightness and contrast, normalization is often applied. The normalized cross-correlation can be defined as:\n",
    "\n",
    "$$\n",
    "C_{AB}(\\tau) = \\frac{R_{AB}(\\tau)}{\\sqrt{R_{AA}(0) R_{BB}(0)}}\n",
    "$$\n",
    "\n",
    "\n",
    "where:\n",
    "- $ R_{AA}(0) = R_{AA}(\\tau = 0) = \\sum_{n=0}^{N-1} A[n]^2 $\n",
    "- $ R_{BB}(0) = R_{BB}(\\tau = 0) = \\sum_{n=0}^{M-1} B[n]^2 $\n",
    "\n",
    "This normalization ensures that the cross-correlation values are bounded between -1 and 1, allowing for a more interpretable measure of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e371e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.learn.analysis import cross_correlate\n",
    "\n",
    "cross_correlate(\n",
    "    input_dataframe=dynamics,\n",
    "    output_graph_file=output_graph_file,\n",
    "    index_column=time_column,\n",
    "    xcorr_configuration_file=model_cfg,\n",
    "    dropna=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(output_graph_file, \"r\") as file:\n",
    "    loaded_json = json.load(file)\n",
    "\n",
    "data = loaded_json[\"graph\"]\n",
    "\n",
    "nodes = set()\n",
    "links = []\n",
    "\n",
    "for link in data[\"links\"]:\n",
    "    nodes.add(link[\"source\"])\n",
    "    nodes.add(link[\"target\"])\n",
    "    links.append(\n",
    "        {\"source\": link[\"source\"], \"target\": link[\"target\"], \"value\": link[\"value\"]}\n",
    "    )\n",
    "\n",
    "node_list = []\n",
    "for node in nodes:\n",
    "    node_list.append(\n",
    "        {\n",
    "            \"name\": node,\n",
    "            \"symbolSize\": 20,\n",
    "            \"value\": f\"{node} - {len([link for link in links if link['source'] == node or link['target'] == node])} bound(s)\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "graph = (\n",
    "    Graph()\n",
    "    .add(\"\", node_list, links, repulsion=8000)\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"2D Dependency Graph\"),\n",
    "        tooltip_opts=opts.TooltipOpts(trigger=\"item\", formatter=\"{b}: {c}\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "graph.render_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
